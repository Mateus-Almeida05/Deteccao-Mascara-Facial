{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Detector de M√°scara**"
      ],
      "metadata": {
        "id": "i-K3vlfzMbSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse c√≥digo √© um exemplo de aplica√ß√£o pr√°tica de vis√£o computacional usando OpenCV e um modelo de deep learning treinado em Keras para detec√ß√£o de m√°scara facial.\n",
        "\n",
        "O c√≥digo acessa a webcam, detecta rostos usando Haar Cascade, recorta e pr√©-processa cada face e passa pela rede neural treinada (mask_detector.h5). Em tempo real, ele exibe se a pessoa est√° com m√°scara (verde) ou sem m√°scara (vermelho), junto com a probabilidade da predi√ß√£o.\n",
        "\n",
        "O arquivo com extens√£o .h5 √© um formato HDF5 (Hierarchical Data Format v5), usado para armazenar modelos treinados em Keras/TensorFlow. Ele funciona como um \"pacote\" que guarda tanto a arquitetura da rede neural quanto os pesos aprendidos durante o treinamento.\n",
        "\n",
        "No contexto de projetos como o de detec√ß√£o de m√°scara facial, o .h5 √© essencial porque cont√©m:\n",
        "\n",
        "   - Arquitetura do modelo ‚Üí descreve as camadas (Dense, Convolutional, etc.), fun√ß√µes de ativa√ß√£o e conex√µes entre elas.\n",
        "\n",
        "   - Pesos treinados ‚Üí os par√¢metros que a rede ajustou durante o treinamento, respons√°veis por reconhecer padr√µes nas imagens.\n",
        "\n",
        "   - Configura√ß√µes adicionais ‚Üí como fun√ß√£o de perda (loss function), otimizador e m√©tricas.\n",
        "\n",
        "Na pr√°tica: Em vez de treinar a rede toda vez, basta carregar o arquivo .h5 j√° treinado."
      ],
      "metadata": {
        "id": "MQ_3FMdLT6nl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSQ5Vz_b5dn-"
      },
      "outputs": [],
      "source": [
        "#Importa√ß√µes\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#Carrega o modelo treinado\n",
        "cnn = load_model(\"mask_detector.h5\")\n",
        "\n",
        "#Ajuste dos labels (este modelo pode usar 0 = Mask, 1 = No Mask)\n",
        "labels_dict = {0: 'Mask', 1: 'No Mask'}\n",
        "color_dict = {0: (0, 255, 0), 1: (0, 0, 255)}  # Verde = m√°scara, Vermelho = sem m√°scara\n",
        "\n",
        "#Configura√ß√£o da c√¢mera e detector de rosto\n",
        "imgsize = 4\n",
        "camera = cv2.VideoCapture(0)\n",
        "\n",
        "classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "print(\"‚ñ∂ Webcam ligada. Pressione ESC para sair.\")\n",
        "\n",
        "#Loop de captura de v√≠deo\n",
        "while True:\n",
        "    (rval, im) = camera.read()\n",
        "    if not rval:\n",
        "        print(\"‚ùå N√£o foi poss√≠vel acessar a webcam.\")\n",
        "        break\n",
        "\n",
        "    #Detec√ß√£o de rostos\n",
        "    im = cv2.flip(im, 1, 1)\n",
        "    imgs = cv2.resize(im, (im.shape[1] // imgsize, im.shape[0] // imgsize))\n",
        "    face_rec = classifier.detectMultiScale(imgs)\n",
        "\n",
        "    for i in face_rec:\n",
        "        (x, y, l, w) = [v * imgsize for v in i]\n",
        "        face_img = im[y:y+w, x:x+l]\n",
        "\n",
        "        # Pr√©-processamento (224x224, normalizado)\n",
        "        resized = cv2.resize(face_img, (224, 224))\n",
        "        normalized = resized.astype(\"float32\") / 255.0\n",
        "        reshaped = np.reshape(normalized, (1, 224, 224, 3))\n",
        "\n",
        "        # Predi√ß√£o\n",
        "        result = cnn.predict(reshaped, verbose=0)\n",
        "        label = np.argmax(result, axis=1)[0]\n",
        "        prob = np.max(result) * 100  # pega a maior probabilidade\n",
        "\n",
        "        # Desenho na imagem\n",
        "        cv2.rectangle(im, (x, y), (x+l, y+w), color_dict[label], 2)\n",
        "        cv2.rectangle(im, (x, y-40), (x+l, y), color_dict[label], -1)\n",
        "\n",
        "        text = f\"{labels_dict[label]} ({prob:.1f}%)\"\n",
        "        cv2.putText(im, text, (x, y-10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "\n",
        "    #Exibir janela de v√≠deo\n",
        "    cv2.imshow('LIVE', im)\n",
        "\n",
        "    #Encerramento\n",
        "    key = cv2.waitKey(10)\n",
        "    if key == 27:  # ESC\n",
        "        print(\"üëã Encerrando...\")\n",
        "        break\n",
        "\n",
        "camera.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O projeto desenvolvido demonstra de forma eficaz a aplica√ß√£o pr√°tica de t√©cnicas de vis√£o computacional e aprendizado profundo para a detec√ß√£o autom√°tica do uso de m√°scaras faciais em tempo real. A integra√ß√£o entre o modelo treinado em deep learning e a captura de v√≠deo via webcam permitiu uma an√°lise instant√¢nea e precisa, identificando se o usu√°rio est√° ou n√£o utilizando m√°scara.\n",
        "\n",
        "O sistema apresentou bom desempenho mesmo em hardware limitado, gra√ßas √† efici√™ncia do modelo e √† utiliza√ß√£o otimizada dos recursos computacionais. O feedback visual, baseado em cores e probabilidades, tornou a interface intuitiva e de f√°cil interpreta√ß√£o pelo usu√°rio."
      ],
      "metadata": {
        "id": "ifomUkOVk5N_"
      }
    }
  ]
}